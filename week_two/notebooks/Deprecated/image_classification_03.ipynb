{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "446ae1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76f6892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "838ef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data, class_list=None):\n",
    "    image, label = data\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "        \n",
    "    if class_list:\n",
    "        label = class_list[label]\n",
    "        \n",
    "    plt.title(label)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a58d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST(root='./data',\n",
    "                                   transform=torchvision.transforms.ToTensor(),\n",
    "                                   download=True,\n",
    "                                   train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fffac9",
   "metadata": {},
   "source": [
    "If you recall, our breakdown of machine learning was:\n",
    "- data\n",
    "- model\n",
    "- training.\n",
    "And we are trying to cover the paper [Backpropagation Applied to Handwritten Zip Code Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf). \n",
    "\n",
    "We just covered data, so we'll move onto learning about the model.\n",
    "\n",
    "A neural network model has several basic components:\n",
    "- neural network layer;\n",
    "- activation function;\n",
    "- loss function.\n",
    "We will cover all of these, beginning with the neural network layers.\n",
    "But first, we'll have to make a short digression.\n",
    "\n",
    "The original LeNet model took in a $16 \\times 16$ image and its output was a 10 dimensional vector.\n",
    "So, if we input an image of a 5 into the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceaa74fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(mnist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd9f52",
   "metadata": {},
   "source": [
    "Then the model should output a vector that is close to this one:\n",
    "$$ [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] $$\n",
    "\n",
    "The above vector is an example of one-hot encoding.\n",
    "The idea is that if we have $C$ classes, then we want a $C$ dimensional vector that has $0$s in everything, except the class we want to predict. This will be a one.\n",
    "\n",
    "To explain this more, suppose that we want to predict one of the four letters $A, B, C, D$.\n",
    "Then we could one-hot encode it as:\n",
    "$$ A \\rightarrow [1, 0, 0, 0]$$\n",
    "$$ B \\rightarrow [0, 1, 0, 0]$$\n",
    "$$ C \\rightarrow [0, 0, 1, 0]$$\n",
    "$$ D \\rightarrow [0, 0, 0, 1]$$\n",
    "\n",
    "We don't have to have this correspondence.\n",
    "We could have another one, such as:\n",
    "$$ D \\rightarrow [1, 0, 0, 0]$$\n",
    "$$ A \\rightarrow [0, 1, 0, 0]$$\n",
    "$$ C \\rightarrow [0, 0, 1, 0]$$\n",
    "$$ B \\rightarrow [0, 0, 0, 1]$$\n",
    "\n",
    "The imporant thing is that once we decide on this correspondence it needs to be fixed.\n",
    "One data structure that can help with this is the `dict` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "650f77af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([1, 0, 0, 0]),\n",
       " 'B': array([0, 1, 0, 0]),\n",
       " 'C': array([0, 0, 1, 0]),\n",
       " 'D': array([0, 0, 0, 1])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {'A': np.array([1, 0, 0, 0]),\n",
    "              'B': np.array([0, 1, 0, 0]),\n",
    "              'C': np.array([0, 0, 1, 0]),\n",
    "              'D': np.array([0, 0, 0, 1])}\n",
    "\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e74c907",
   "metadata": {},
   "source": [
    "How would we make this into a function?\n",
    "We want to take in classes and output a correspondence between the classes and the one-hot encoding.\n",
    "\n",
    "- What do you think a good name would be?\n",
    "- What should the inputs be?\n",
    "- What should the ouptuts be?\n",
    "\n",
    "We're going to work on this question together right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2771c",
   "metadata": {},
   "source": [
    "def one_hot():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f4bd2",
   "metadata": {},
   "source": [
    "Or the too clever way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5d12cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(classes):\n",
    "    num_classes = len(classes)\n",
    "    ident = np.eye(num_classes)\n",
    "\n",
    "    class_dict = {classes[i]: ident[i] for i in range(num_classes)}\n",
    "\n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72770971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([1., 0., 0., 0.]),\n",
       " 'B': array([0., 1., 0., 0.]),\n",
       " 'C': array([0., 0., 1., 0.]),\n",
       " 'D': array([0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(['A', 'B', 'C', 'D'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df092a0",
   "metadata": {},
   "source": [
    "Back to the model.\n",
    "\n",
    "We want the LeNet model to output a 10-dimensional vector, because there are 10 classes we want to predict: the 10 digits.\n",
    "We'll go into more detail about this later when we talk about loss functions and training.\n",
    "\n",
    "The first thing we input into our model is an image converted to an $28 \\times 28$ array of numbers!\n",
    "This is sometimes called the **input layer**.\n",
    "\n",
    "After we input the image, the next layer is called a **convolutional layer**.\n",
    "The convolutional layer as a neural network layer was developed by Kunihiko Fukushima.\n",
    "He developed it for his neural network based handwriting recognition model called the **neocognitron**.\n",
    "The convolutional layer consists of several convolutional kernels that operate on the image.\n",
    "Let's go through an example.\n",
    "We'll take a $3 \\times 3$ kernel and have it operate on a $5 \\times 5$ image.\n",
    "\n",
    "Our $3 \\times 3$ kernel will be:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "and we'll work on the $5 \\times 5$ matrix:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "4 & 4 & 2 & 4 & 4 \\\\\n",
    "5 & 3 & 4 & 0 & 3 \\\\\n",
    "1 & 0 & 2 & 3 & 0 \\\\\n",
    "5 & 4 & 2 & 4 & 5 \\\\\n",
    "0 & 0 & 4 & 3 & 2 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The $3 \\times 3$ kernel is one of the Prewitt operator, used for edge detection.\n",
    "Did you notice something about what happened to the size of the $5 \\times 5$ matrix after we did a convolution on it with $3 \\times 3$ kernel?\n",
    "The height and width both dropped by 2.\n",
    "\n",
    "If we used\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "-1 & -1 & -1 \\\\\n",
    " 0 &  0 &  0 \\\\\n",
    " 1 &  1 &  1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "as our convolutional kernels and we put in a $1 \\times 28 \\times 28$ MNIST image, we would get out a $2 \\times 26 \\times 26$ tensor.\n",
    "If we wanted to keep the same height and width, 28, then we can do something called padding.\n",
    "Padding is just adding different values to the edge of our input.\n",
    "\n",
    "Pytorch has a couple ways to do this padding operation, but the primary way we'll deal with it is as a parameter in our convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28abad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 30])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, _ = mnist[0]\n",
    "\n",
    "# We choose 1. as the value below, because it's easier to see in the image that we padded it.\n",
    "padded_image = F.pad(image, pad=(1, 1, 1, 1), value=1.)\n",
    "padded_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28e1b8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image((padded_image, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae16da18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(mnist[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65e2fc",
   "metadata": {},
   "source": [
    "Let's look closer at our the convolutional layer in Pytorch\n",
    "\n",
    "`torch.nn.Conv2d(in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 bias)`\n",
    "                 \n",
    "Let's go through some of the parameters:\n",
    "- `in_channels`: this is the number of channels in our input. So, if we input a (3, 224, 224) tensor, we would set the value of this to 3.\n",
    "- `out_channels`: this is the number of channels we want to ouptut. If we want to have 6 channels out, we would set this to 6.\n",
    "- `kernel_size`: this is the size of the kernel; above we had a $3 \\times 3$ kernel, so this would be set to 3.\n",
    "- `stride`: this is how many element to skip over; above we had a stride of 1.\n",
    "- `padding`: we talked about this above.\n",
    "- `bias`: this would be a tensor the same shape as our output; this would be added to the output before its sent to the next layer.\n",
    "\n",
    "Let's look at an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b5fb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = torch.nn.Conv2d(1, 6, 3, stride=1, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4308824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 28, 28])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa468a0",
   "metadata": {},
   "source": [
    "So, we have the first layer down.\n",
    "The next layer is what is called a pooling layer.\n",
    "There are typically two types of these layers: max pooling and average pooling.\n",
    "The purpose of these is to reduce the input size to the next layer in order to reduce the parameter size of the next layer.\n",
    "\n",
    "Let's talk about both max pooling and average pooling.\n",
    "For max pooling, our kernel just chooses the largest element in the kernel.\n",
    "With these operations, you should think of the kernel as a sliding window.\n",
    "Let's look at an example of this.\n",
    "We'll look at a $2\\times 2$ and $3 \\times 3$ kernel on the matrix:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "4 & 4 & 2 & 4 & 4 \\\\\n",
    "5 & 3 & 4 & 0 & 3 \\\\\n",
    "1 & 0 & 2 & 3 & 0 \\\\\n",
    "5 & 4 & 2 & 4 & 5 \\\\\n",
    "0 & 0 & 4 & 3 & 2 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "If we perform max pooling with a $2 \\times 2$ kernel, we get:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5 & 4 & 4 & 4 \\\\\n",
    "5 & 4 & 4 & 3 \\\\\n",
    "5 & 4 & 4 & 5 \\\\\n",
    "5 & 4 & 4 & 5\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "and with a $3 \\times 3$ kernel, we get:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5 & 4 & 4 \\\\\n",
    "5 & 4 & 4 \\\\\n",
    "5 & 4 & 5\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "I know this is tedious.\n",
    "This is why we invented and used computers!\n",
    "Now, let's look at the average pooling case on the same matrix.\n",
    "With a $2 \\times 2$ kernel we get:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "   4 & 3.25 & 2.5  & 2.75 \\\\\n",
    "2.25 & 2.75 & 2.25 & 1.5  \\\\\n",
    "2.5  & 2    & 2.75 & 3    \\\\\n",
    "2.25 & 2.5  & 3.25 & 3.5\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "with a $3 \\times 3$ kernel we get:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "2.7778 & 2.4444 & 2.4444 \\\\\n",
    "2.8889 & 2.4444 & 2.5556 \\\\\n",
    "2.0000 & 2.4444 & 2.7778\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5f28834",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[\n",
    "    [4, 4, 2, 4, 4],\n",
    "    [5, 3, 4, 0, 3],\n",
    "    [1, 0, 2, 3, 0],\n",
    "    [5, 4, 2, 4, 5],\n",
    "    [0, 0, 4, 3, 2]\n",
    "]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed56429e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7778, 2.4444, 2.4444],\n",
       "         [2.8889, 2.4444, 2.5556],\n",
       "         [2.0000, 2.4444, 2.7778]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.AvgPool2d(kernel_size=(3, 3), stride=1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed344757",
   "metadata": {},
   "source": [
    "That was much easier to calculate, right?\n",
    "\n",
    "For our model, we're going to use the average pooling layer.\n",
    "Let's look at the Pytorch layer:\n",
    "`torch.nn.AvgPool2d(kernel_size,\n",
    "                    stride,\n",
    "                    padding)`\n",
    "\n",
    "- `kernel_size`: this is just the size of our sliding window.\n",
    "- `stride`: this is exactly the same as in the `torch.nn.Conv2d` case; it just tells us how many steps to take.\n",
    "- `padding`: this is exactly the same as in the `torch.nn.Conv2d` case; again, it tells us how many zeroes to pad our tensor with; this allows us to control the size of the output.\n",
    "\n",
    "`torch.nn.AvgPool2d` can be written as a kernel, let's spend a few minutes trying to figure out out how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae90d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 1 / 9 * torch.ones((1, 1, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e81cf408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.7778, 2.4444, 2.4444],\n",
       "         [2.8889, 2.4444, 2.5556],\n",
       "         [2.0000, 2.4444, 2.7778]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv2d(x, weight=weight, stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ae2b3",
   "metadata": {},
   "source": [
    "Since we want a specific layer, we called `F.conv2d` as opposed to `torch.nn.Conv2d`.\n",
    "As you see, we can do a convolution to get the same result as average pooling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5367b",
   "metadata": {},
   "source": [
    "The next layer is another convolutional layer.\n",
    "What we're going to do is not exactly what was done in the LeNet paper, but it's a close enough approximation.\n",
    "The next layer is\n",
    "\n",
    "`torch.nn.Conv2d(in_channels=6,\n",
    "                 out_channels=16,\n",
    "                 kernel_size=5,\n",
    "                 stride=1,\n",
    "                 padding=0)`\n",
    "                 \n",
    "We should note that we can omit putting in `padding=0` and `stride=1`, because they are both default values.\n",
    "\n",
    "This convolutional layer is immediately followed by the same type of pooling layer as before:\n",
    "\n",
    "`torch.nn.AvgPool2d(kernel_size=2,\n",
    "                    stride=2,\n",
    "                    padding=0)`\n",
    "                    \n",
    "As before, we can omit `padding=0`, because it is a default value.\n",
    "\n",
    "If we input a tensor of shape (1, 28, 28), that represents a black and white image, then the output at this point is a tensor of shape (16, 5, 5).\n",
    "\n",
    "We want to input this into what is called a **linear** layer or a **fully connected** layer.\n",
    "The input to this layer has to be a tensor of shape $(m, )$, also known as an $m$-dimensional vector.\n",
    "We need an $(n, m)$ matrix that we denote by $\\textbf{W}$.\n",
    "With neural networks, this is called a **weight** matrix.\n",
    "We also have an optional parameter called the **bias**.\n",
    "This is a vector of shame $(n, )$, because it's added after the multiplication.\n",
    "Remember that the output of an $(n, m)$ matrix multiplied by a $(m, )$ vector is a $(n, )$ vector.\n",
    "\n",
    "The problem we have is our tensor is the wrong shape, if we try to input it into the linear layer, we'll get a shape error.\n",
    "What we need to do is change the shape of this tensor somehow.\n",
    "What shape should it have if we change it?\n",
    "\n",
    "The function we want is available within Pytorch and it's called `torch.flatten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "088d95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0354b9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18eba1",
   "metadata": {},
   "source": [
    "As we saw, our input was a tensor of shape (3, 4, 5) and it's output was a tensor of shape (60,).\n",
    "What is $3 \\times 4 \\times 5$?\n",
    "\n",
    "`torch.flatten` has three parameters:\n",
    "- `input`: this is just the tensor that we want to flatten.\n",
    "- `start_dim`: this is the start of the dimension we want to flatten.\n",
    "- `end_dim`: this is the end of the dimensions we want to flatten.\n",
    "\n",
    "If we don't input anything for `start_dim` and `end_dim`, they default to flattening everything.\n",
    "\n",
    "Let's look at another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a4ae537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 5, 6, 7, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfe2048",
   "metadata": {},
   "source": [
    "If we call\n",
    "\n",
    "`torch.flatten(x, start_dim=1, end_dim=3)`\n",
    "\n",
    "then what will the shame of $x$ be?\n",
    "Let's take a minute to guess before we input it into the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97060143",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(x, start_dim=1, end_dim=3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152fe43",
   "metadata": {},
   "source": [
    "Back to our LeNet model.\n",
    "We want to flatten everything in our (16, 5, 5)-tensor.\n",
    "This gives us a tensor of shape (400, ).\n",
    "\n",
    "Recall that we talked about the stride of a tensor last Friday.\n",
    "So, `torch.flatten` works by changing the stride of the tensor!\n",
    "\n",
    "So, we have a (400, )-tensor going into our fully connnected layer.\n",
    "For the paper, they wanted an (84, )-tensor as output.\n",
    "The way we would create this layer is\n",
    "\n",
    "`torch.nn.Linear(400, 84)`\n",
    "\n",
    "This is a simpler layer than other ones.\n",
    "We only have three parameters for it:\n",
    "\n",
    "`torch.nn.Linear(in_features, out_features, bias)`\n",
    "\n",
    "- `in_features`: This is the size of the tensor/vector coming in.\n",
    "- `out_features`: This is what size we want to the tensor/vector to come out as.\n",
    "- `bias`: If we want to add a vector to it at the end, we would include this one.\n",
    "\n",
    "The default of `bias` is `True`, so we typically don't include it.\n",
    "\n",
    "So, we have an (84, )-tensor as our input now and at this point we want to make a prediction.\n",
    "We have 10 classes, so we want 10 outputs.\n",
    "So, our last layer is\n",
    "\n",
    "`torch.nn.Linear(84, 10)`.\n",
    "\n",
    "We said there were some basic components to neural networks:\n",
    "- neural network layer;\n",
    "- activation function;\n",
    "- loss function.\n",
    "\n",
    "We only covered neural network layer so far.\n",
    "We're going to cover activation function next.\n",
    "\n",
    "Because of the way matrix multiplication works if we have two layers and no activation function between, it's the same as just having one neural network layer.\n",
    "This is why we need an activation function.\n",
    "The activation function that the LeNet model used was what's called a **hyperbolic tangent** function.\n",
    "This function is defined as\n",
    "$$\n",
    "\\operatorname{tanh}(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
    "$$\n",
    "and here is a picture of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e3668abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.01)\n",
    "y = np.tanh(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f447058",
   "metadata": {},
   "source": [
    "Activation functions act on tensors point-wise.\n",
    "So, if we have\n",
    "$$\n",
    "\\textbf{X} = \n",
    "\\begin{pmatrix}\n",
    "1 & 3 & 4 \\\\\n",
    "-4 & 0 & -1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "the ouput of $\\operatorname{tanh}(\\textbf{X})$ is \n",
    "$$\n",
    "\\operatorname{tanh}(\\textbf{X}) =\n",
    "\\begin{pmatrix}\n",
    "\\operatorname{tanh}(1)  & \\operatorname{tanh}(3) & \\operatorname{tanh}(4) \\\\\n",
    "\\operatorname{tanh}(-4) & \\operatorname{tanh}(0) & \\operatorname{tanh}(-1) \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "So, we put `torch.tanh` between each layer.\n",
    "\n",
    "Finally, we need to cover the loss function.\n",
    "In the LeNet paper, they used what is called **mean squared error**.\n",
    "Suppose that\n",
    "$$\n",
    "\\widehat{\\textbf{y}} = (\\widehat{y_{1}}, \\ldots, \\widehat{y_{n}})\n",
    "$$\n",
    "is our prediction and\n",
    "$$\n",
    "\\textbf{y} = (y_{1}, \\ldots, y_{n})\n",
    "$$\n",
    "is our label, then the mean squared error is defined as\n",
    "$$\n",
    "\\operatorname{MSE}(\\widehat{\\textbf{y}}, \\textbf{y}) =\n",
    "\\sqrt{(y_{1} - \\widehat{y}_{1})^{2} + \\cdots + (y_{n} - \\widehat{y}_{n})^{2}}\n",
    "$$\n",
    "\n",
    "Let's take a minute to see if we can implement this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f3fa34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred, label):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec67f0",
   "metadata": {},
   "source": [
    "I will warn you that this isn't the best loss function to use for our purposes.\n",
    "The reason we're using it here is because it was used in the original LeNet paper.\n",
    "We will go over a better one later.\n",
    "\n",
    "Now we have to put it all together!\n",
    "There are several ways to do this, but we'll primarily be doing the `class` based method.\n",
    "\n",
    "All of our models will be subclasses of the `torch.nn.Module` class.\n",
    "I'll create a single layer neural network model to show how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "67032d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=28 * 28, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.lin_layer = torch.nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.lin_layer(x)\n",
    "        return torch.nn.LogSoftmax(dim=-1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d4d31e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize(mean=torch.tensor([0.1307]), std=torch.tensor([0.3081]))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "71af6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.MNIST(root='./data',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transforms)\n",
    "\n",
    "test_ds = torchvision.datasets.MNIST(root='./data',\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0ea9849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds,\n",
    "                                       batch_size=len(train_ds),\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=4)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds,\n",
    "                                      batch_size=len(test_ds),\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "945bc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FirstModel()\n",
    "criterion = torch.nn.NLLLoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fcacc6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirstModel(\n",
       "  (lin_layer): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "afba80eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 2 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 3 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 4 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 5 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 6 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 7 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 8 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 9 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 11 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 12 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 13 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 14 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 15 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 16 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 17 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 18 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 19 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 20 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 21 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 22 epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f98ee5f0b80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1359, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1342, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 23 epoch.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(23):\n",
    "    for inputs, label in train_dl:\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "        \n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(f\"Finished epoch {epoch + 1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "daa752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, label in test_loader:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "    print(f'Accuracy of the network on 10000 test images: {100 * correct // total} %')\n",
    "    return 100 * correct // total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "181aeac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 10000 test images: 67 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b576b",
   "metadata": {},
   "source": [
    "Now, you're going to implement the LeNet model yourself!\n",
    "We'll have the boiler plate, but you'll have to implement `__init__` and `__forward__` methods yourself.\n",
    "I will put the information about the layers here\n",
    "\n",
    "- Convolutional layer\n",
    "    - in channels: 1\n",
    "    - out channels: 6\n",
    "    - kernel size: 5\n",
    "    - padding: 2\n",
    "- Average Pooling\n",
    "    - kernel size: 2\n",
    "    - stride: 2\n",
    "- Convolutional Layer\n",
    "    - in channels: 6\n",
    "    - out channels: 16\n",
    "    - kernel size: 5\n",
    "- Average Pooling\n",
    "    - kernel size: 2\n",
    "    - stride: 2\n",
    "- Flatten\n",
    "- Linear Layer\n",
    "    - in features: 400\n",
    "    - out features: 120\n",
    "- Linear Layer\n",
    "    - in features: 120\n",
    "    - out features: 84\n",
    "- Linear Layer\n",
    "    - in features: 84\n",
    "    - out features: 10\n",
    "- Activation: `torch.tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "585cfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b786eb6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [198]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLeNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36mLeNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model, train_dl, test_dl, epochs=23, evaluate=True):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for inputs, label in train_dl:\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            out = model(inputs)\n",
    "            loss = criterion(out, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        print(f\"Finished epoch {epoch + 1}.\")\n",
    "    print(f\"Finished Training!\")\n",
    "    if evaluate:\n",
    "        print(\"Evaluating\")\n",
    "        evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "244d65a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [199]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLeNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36mLeNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dl, test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
