{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33860822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "    \n",
    "    ckpt_dict = torch.load(path)\n",
    "    \n",
    "    model.load_state_dict(ckpt_dict['model_state_dict'])\n",
    "    \n",
    "    return ckpt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_onnx(model, input_shape, path=None):\n",
    "    bs, c, h, w = input_shape\n",
    "    \n",
    "    dummy_input = torch.randn(bs, c, h, w, device='cuda')\n",
    "    \n",
    "    model.to('cuda')\n",
    "    \n",
    "    input_names = [ \"input\" ]\n",
    "    output_names = [ \"output\" ]\n",
    "    \n",
    "    if not path:\n",
    "        path = model.__class__.__name__ + '.onnx'\n",
    "    \n",
    "    torch.onnx.export(model, dummy_input, path, verbose=True, input_names=input_names, output_names=output_names)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d15c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_loader):\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        t = time.time()\n",
    "        for i, (inputs, label) in enumerate(test_loader):\n",
    "            inputs, label = inputs.to(device), label.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(label.size(0))\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "            t = time.time() - t\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(\"Batch     | Time(s)\")\n",
    "            print(\"-------------------\")\n",
    "            print(f\"{i + 1:5d} / {len(test_loader):5d} | {int(t):7d}\")\n",
    "\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "            \n",
    "    print(f'Accuracy of the network on {len(test_loader.dataset)} test images: {accuracy:.1f} %')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0230cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'lr': 3e-3,\n",
    "    'num_classes': 16, # Don't change\n",
    "    # Decide whether you want to add mixup training and how often it is run..\n",
    "    'mixup': True,\n",
    "    'mixup_pct': 0.90,\n",
    "    # Automatic Mixed Precision, should speed up training.\n",
    "    'use_amp': True,\n",
    "    # Epochs - how long you want to train\n",
    "    'epochs': 20,\n",
    "    'start_epoch': 0,\n",
    "    # Pin the memory, this should speed up training, but could make the kernel more stable\n",
    "    'pin_memory': True, # Don't change\n",
    "    # This is your batch size.\n",
    "    'bs': 256,\n",
    "    # Whether or not to use stochastic weight averaging. Setting to true should increase test accuracy.\n",
    "    # If use_swa is set to False, then swa_start and swa_lr is not used.\n",
    "    'use_swa': True,\n",
    "    'swa_start': 17,\n",
    "    'swa_lr': 5e-3,\n",
    "    # How many epochs to train before saving model. If set to 0, checkpointing will not be performed.\n",
    "    'checkpoint': 10,\n",
    "    # Where your training data is stored.\n",
    "    'train_root': '/workspace/data/LAICC_2023/training/', # Do not change\n",
    "    # Where your test data is stored.\n",
    "    'test_root': '/workspace/data/LAICC_2023/test/', # Do not change\n",
    "    # This should be a number and how often you should save your data.\n",
    "    'num_workers': 4,\n",
    "    # If you want to restart training, change this to the path of the checkpoint you wish to start at.\n",
    "    'ckpt_path': None, #'/workspace/models/ResNet_Lakota_Plants_1658958130.ckpt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose(\n",
    "    [#T.Resize(size=(246, 246)),\n",
    "     T.CenterCrop([224]),\n",
    "     T.AugMix(),\n",
    "     #T.RandomPerspective(),\n",
    "     T.RandomHorizontalFlip(p=0.5),\n",
    "     T.RandomVerticalFlip(p=0.5),\n",
    "     T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1)),\n",
    "     T.RandomRotation(degrees=(0, 10)),\n",
    "     #T.Grayscale(num_output_channels=3),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225])),\n",
    "    ])\n",
    "\n",
    "test_transforms = T.Compose(\n",
    "    [#T.Resize(size=(246, 246)),\n",
    "     T.CenterCrop([224]),\n",
    "     #T.Grayscale(num_output_channels=3),\n",
    "     T.ToTensor(),\n",
    "     T.Normalize(mean=torch.tensor([0.485, 0.456, 0.406]), std=torch.tensor([0.229, 0.224, 0.225])),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchvision.datasets.ImageFolder(root=hparams['train_root'], transform=transforms,\n",
    "                                            target_transform=None, loader=Image.open,\n",
    "                                            is_valid_file=None)\n",
    "\n",
    "test_ds = torchvision.datasets.ImageFolder(root=hparams['test_root'], transform=test_transforms,\n",
    "                                            target_transform=None, loader=Image.open,\n",
    "                                            is_valid_file=None)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_ds,\n",
    "                                      batch_size=hparams['bs'],\n",
    "                                      shuffle=False,\n",
    "                                      sampler=None,\n",
    "                                      num_workers=hparams['num_workers'],\n",
    "                                      persistent_workers=False,\n",
    "                                      pin_memory=hparams['pin_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a794fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(model.fc.in_features, len(train_ds.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837be2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_path = os.path.join('/workspace/models',\n",
    "                          'ResNet_Lakota_Plants_1687817041.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dict = load_model(model, chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbdcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d24e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d762bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eade9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes= len(train_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934365cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF you are satisfied with your models performance, save to ONNX\n",
    "# You need to change your input shape. It should be of the form\n",
    "# (batch_size, num_channels, height, width)\n",
    "# You will get height and width from the transform\n",
    "# T.Resize(size=(224, 224)), which would mean we would have\n",
    "input_shape = (10, 3, 224, 224)\n",
    "\n",
    "\n",
    "onnx_path = f'/workspace/models/{model.__class__.__name__}18_{num_classes}classes_{device}_{acc:.2f}_{int(time.time())}.onnx'\n",
    "\n",
    "save_to_onnx(model, input_shape, path=onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e72f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_path = f'/workspace/models/{model.__class__.__name__}18_{num_classes}classes_{device}_{acc:.2f}_{int(time.time())}.pt'\n",
    "\n",
    "torch.save(model, torch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56430ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
